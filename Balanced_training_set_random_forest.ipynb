{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3zJrHl2YYkg",
    "outputId": "58ecabce-098d-472e-948f-46ef6724ba05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from google.colab import drive\\ndrive.mount(\"/content/gdrive\")'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iibLSvrIa4nu"
   },
   "source": [
    "# **Prepare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "cW6UFHEBS_1G",
    "outputId": "47d67550-a4b1-4269-f402-7105f65e0d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-3.0.2+computecanada-py3-none-any.whl\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Using cached tokenizers-0.8.1rc1.tar.gz (97 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in ./jp1/lib/python3.10/site-packages (from transformers==3.0.2) (0.1.97)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./jp1/lib/python3.10/site-packages (from transformers==3.0.2) (2022.1.18+computecanada)\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sacremoses-0.0.49+computecanada-py3-none-any.whl\n",
      "Requirement already satisfied: packaging in ./jp1/lib/python3.10/site-packages (from transformers==3.0.2) (21.3+computecanada)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./jp1/lib/python3.10/site-packages (from transformers==3.0.2) (4.64.1+computecanada)\n",
      "Requirement already satisfied: filelock in ./jp1/lib/python3.10/site-packages (from transformers==3.0.2) (3.8.2)\n",
      "Requirement already satisfied: requests in ./jp1/lib/python3.10/site-packages (from transformers==3.0.2) (2.28.1+computecanada)\n",
      "Requirement already satisfied: numpy in ./jp1/lib/python3.10/site-packages (from transformers==3.0.2) (1.23.0+computecanada)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./jp1/lib/python3.10/site-packages (from packaging->transformers==3.0.2) (3.0.9+computecanada)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./jp1/lib/python3.10/site-packages (from requests->transformers==3.0.2) (1.26.13+computecanada)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./jp1/lib/python3.10/site-packages (from requests->transformers==3.0.2) (2.1.1+computecanada)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jp1/lib/python3.10/site-packages (from requests->transformers==3.0.2) (2022.9.24+computecanada)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jp1/lib/python3.10/site-packages (from requests->transformers==3.0.2) (3.4+computecanada)\n",
      "Requirement already satisfied: click in ./jp1/lib/python3.10/site-packages (from sacremoses->transformers==3.0.2) (8.1.3+computecanada)\n",
      "Requirement already satisfied: six in ./jp1/lib/python3.10/site-packages (from sacremoses->transformers==3.0.2) (1.16.0+computecanada)\n",
      "Requirement already satisfied: joblib in ./jp1/lib/python3.10/site-packages (from sacremoses->transformers==3.0.2) (1.2.0+computecanada)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[48 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-awoswh_r/overlay/lib/python3.10/site-packages/setuptools/dist.py:534: UserWarning: Normalizing '0.8.1.rc1' to '0.8.1rc1'\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(tmpl.format(**locals()))\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/models/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/decoders/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/normalizers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/pre_tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/processors/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/trainers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/sentencepiece_bpe.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/char_level_bpe.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/byte_level_bpe.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/bert_wordpiece.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/base_tokenizer.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/models/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/decoders/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/normalizers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/pre_tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/processors/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/trainers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m running build_rust\n",
      "  \u001b[31m   \u001b[0m error: can't find Rust compiler\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m To update pip, run:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     pip install --upgrade pip\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m and then retry package installation.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build tokenizers\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: torch in ./jp1/lib/python3.10/site-packages (1.13.1+computecanada)\n",
      "Requirement already satisfied: torchvision in ./jp1/lib/python3.10/site-packages (0.14.1+cu116)\n",
      "Requirement already satisfied: torchaudio in ./jp1/lib/python3.10/site-packages (0.13.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in ./jp1/lib/python3.10/site-packages (from torch) (4.4.0+computecanada)\n",
      "Requirement already satisfied: requests in ./jp1/lib/python3.10/site-packages (from torchvision) (2.28.1+computecanada)\n",
      "Requirement already satisfied: numpy in ./jp1/lib/python3.10/site-packages (from torchvision) (1.23.0+computecanada)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./jp1/lib/python3.10/site-packages (from torchvision) (9.2.0+computecanada)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jp1/lib/python3.10/site-packages (from requests->torchvision) (2022.9.24+computecanada)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./jp1/lib/python3.10/site-packages (from requests->torchvision) (2.1.1+computecanada)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./jp1/lib/python3.10/site-packages (from requests->torchvision) (1.26.13+computecanada)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jp1/lib/python3.10/site-packages (from requests->torchvision) (3.4+computecanada)\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: nltk in ./jp1/lib/python3.10/site-packages (3.8)\n",
      "Requirement already satisfied: tqdm in ./jp1/lib/python3.10/site-packages (from nltk) (4.64.1+computecanada)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./jp1/lib/python3.10/site-packages (from nltk) (2022.1.18+computecanada)\n",
      "Requirement already satisfied: joblib in ./jp1/lib/python3.10/site-packages (from nltk) (1.2.0+computecanada)\n",
      "Requirement already satisfied: click in ./jp1/lib/python3.10/site-packages (from nltk) (8.1.3+computecanada)\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: Keras-Preprocessing in ./jp1/lib/python3.10/site-packages (1.1.2+computecanada)\n",
      "Requirement already satisfied: numpy>=1.9.1 in ./jp1/lib/python3.10/site-packages (from Keras-Preprocessing) (1.23.0+computecanada)\n",
      "Requirement already satisfied: six>=1.9.0 in ./jp1/lib/python3.10/site-packages (from Keras-Preprocessing) (1.16.0+computecanada)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==3.0.2\n",
    "'''!pip install transformers==2.9\n",
    "'''\n",
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!pip install nltk\n",
    "!pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UbyLQeCxajSS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6001568/zhe8nov1/jp1/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-06 20:00:04.268480: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 20:00:08.538755: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-06 20:00:33.894437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 20:00:33.896359: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 20:00:33.896392: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "from transformers import DistilBertTokenizer, RobertaTokenizer\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from transformers import TFXLNetModel, XLNetTokenizer\n",
    "import nltk\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers import Concatenate\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig\n",
    "from tqdm import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tOwbMmf4al9k"
   },
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HU7L7PJ_agG2"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.scruples-anecdotes.csv\" ,skip_blank_lines=True)\n",
    "\n",
    "dev =pd.read_csv(\"dev-scruples-anecdotes.csv\", skip_blank_lines=True)\n",
    "\n",
    "test =pd.read_csv(\"test.scruples-anecdotes.csv\", skip_blank_lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(train['text'].isnull().sum())\n",
    "print(dev['text'].isnull().sum())\n",
    "print(test['text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "dev = dev.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train['text'].isnull().sum())\n",
    "print(dev['text'].isnull().sum())\n",
    "print(test['text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gMl9l3G_rqt8"
   },
   "outputs": [],
   "source": [
    "#train_50Percent = train.sample(frac=0.50, random_state=42)\n",
    "train_df = train[['text','binarized_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HYm_AX236DZ0"
   },
   "outputs": [],
   "source": [
    "dev_df = dev[['text','binarized_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "L637VhuITUWb"
   },
   "outputs": [],
   "source": [
    "test_df =  test[['text','binarized_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "GM3SsTtyvBjo",
    "outputId": "d48700bf-a762-4ae5-9855-c9a786d1f7aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binarized_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My boyfriend (well just call him M) and I are ...</td>\n",
       "      <td>RIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nMy really good friend is getting married....</td>\n",
       "      <td>RIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've been very lonely for a long time, few fri...</td>\n",
       "      <td>RIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alt account because friends know my real one. ...</td>\n",
       "      <td>RIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pretty much was hanging out with two friends. ...</td>\n",
       "      <td>WRONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>For reference we're both juniors at a T20 coll...</td>\n",
       "      <td>WRONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>So this just happened and I'm a little taken a...</td>\n",
       "      <td>WRONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>So, I've been friends with someone for a few y...</td>\n",
       "      <td>RIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>My first post!\\n\\nNo words were exchanged in t...</td>\n",
       "      <td>RIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Background info: I’m in college and my dorm is...</td>\n",
       "      <td>WRONG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2343 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text binarized_label\n",
       "0     My boyfriend (well just call him M) and I are ...           RIGHT\n",
       "2      \\n\\nMy really good friend is getting married....           RIGHT\n",
       "3     I've been very lonely for a long time, few fri...           RIGHT\n",
       "4     Alt account because friends know my real one. ...           RIGHT\n",
       "5     Pretty much was hanging out with two friends. ...           WRONG\n",
       "...                                                 ...             ...\n",
       "2494  For reference we're both juniors at a T20 coll...           WRONG\n",
       "2495  So this just happened and I'm a little taken a...           WRONG\n",
       "2497  So, I've been friends with someone for a few y...           RIGHT\n",
       "2498  My first post!\\n\\nNo words were exchanged in t...           RIGHT\n",
       "2499  Background info: I’m in college and my dorm is...           WRONG\n",
       "\n",
       "[2343 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Bkb7_CaVuS6G"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "train_df['num_binarized_label']= label_encoder.fit_transform(train_df['binarized_label'])\n",
    "dev_df['num_binarized_label']= label_encoder.fit_transform(dev_df['binarized_label'])\n",
    "test_df['num_binarized_label']= label_encoder.fit_transform(test_df['binarized_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtzzFdS7q0AY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "1dkD2FK9vKHq",
    "outputId": "f88fe02f-6e1f-4625-fb3e-c66716e538d3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binarized_label</th>\n",
       "      <th>num_binarized_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backstory: So, I got an Xbox one for Christmas...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I work with about six other people at might jo...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Context: There was an Instagram post about unp...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Me and my friends spent sometime organizing a ...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A little background. I'm a far from rich guy w...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27761</th>\n",
       "      <td>So a bit of background info. My girlfriend has...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27762</th>\n",
       "      <td>Context:\\n\\nI’ve been best friends with this g...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27763</th>\n",
       "      <td>So me (19M) and my gf’s (18F) relationship has...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27764</th>\n",
       "      <td>A little info, I’m an Early College student, f...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27765</th>\n",
       "      <td>I was on the way home on a long 2 lane bridge ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text binarized_label  \\\n",
       "0      Backstory: So, I got an Xbox one for Christmas...           RIGHT   \n",
       "1      I work with about six other people at might jo...           RIGHT   \n",
       "2      Context: There was an Instagram post about unp...           RIGHT   \n",
       "3      Me and my friends spent sometime organizing a ...           WRONG   \n",
       "4      A little background. I'm a far from rich guy w...           RIGHT   \n",
       "...                                                  ...             ...   \n",
       "27761  So a bit of background info. My girlfriend has...           RIGHT   \n",
       "27762  Context:\\n\\nI’ve been best friends with this g...           RIGHT   \n",
       "27763  So me (19M) and my gf’s (18F) relationship has...           RIGHT   \n",
       "27764  A little info, I’m an Early College student, f...           RIGHT   \n",
       "27765  I was on the way home on a long 2 lane bridge ...           RIGHT   \n",
       "\n",
       "       num_binarized_label  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        1  \n",
       "4                        0  \n",
       "...                    ...  \n",
       "27761                    0  \n",
       "27762                    0  \n",
       "27763                    0  \n",
       "27764                    0  \n",
       "27765                    0  \n",
       "\n",
       "[26196 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "QExzpQ8u1E1C",
    "outputId": "d2bae9fa-5b45-4e8a-a201-411e535f69d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binarized_label</th>\n",
       "      <th>num_binarized_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Me and my friends spent sometime organizing a ...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A girl I dated a few years ago and I have rema...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TLDR at bottom.\\n\\nSo went to a nice dinner wi...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>For some context, I live in a flatshare with t...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I (24M) have been with my girlfriend(29F) for ...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27742</th>\n",
       "      <td>It all started when I gave her the password to...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27743</th>\n",
       "      <td>Bit of a backstory, my boyfriend and I began d...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27747</th>\n",
       "      <td>I work in a very small team at my company. So ...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27751</th>\n",
       "      <td>On Valentine’s Day, my GF and I had a great di...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27753</th>\n",
       "      <td>So I have very vivid dreams, and last night wa...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5738 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text binarized_label  \\\n",
       "3      Me and my friends spent sometime organizing a ...           WRONG   \n",
       "18     A girl I dated a few years ago and I have rema...           WRONG   \n",
       "22     TLDR at bottom.\\n\\nSo went to a nice dinner wi...           WRONG   \n",
       "27     For some context, I live in a flatshare with t...           WRONG   \n",
       "30     I (24M) have been with my girlfriend(29F) for ...           WRONG   \n",
       "...                                                  ...             ...   \n",
       "27742  It all started when I gave her the password to...           WRONG   \n",
       "27743  Bit of a backstory, my boyfriend and I began d...           WRONG   \n",
       "27747  I work in a very small team at my company. So ...           WRONG   \n",
       "27751  On Valentine’s Day, my GF and I had a great di...           WRONG   \n",
       "27753  So I have very vivid dreams, and last night wa...           WRONG   \n",
       "\n",
       "       num_binarized_label  \n",
       "3                        1  \n",
       "18                       1  \n",
       "22                       1  \n",
       "27                       1  \n",
       "30                       1  \n",
       "...                    ...  \n",
       "27742                    1  \n",
       "27743                    1  \n",
       "27747                    1  \n",
       "27751                    1  \n",
       "27753                    1  \n",
       "\n",
       "[5738 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbl1 = train_df['num_binarized_label'] == 1\n",
    "train_df_1 = pd.DataFrame(train_df[nbl1])\n",
    "train_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "DLAVTtCE1Esy",
    "outputId": "d64c84f1-8e57-45a6-84a6-6029caa99feb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binarized_label</th>\n",
       "      <th>num_binarized_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backstory: So, I got an Xbox one for Christmas...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I work with about six other people at might jo...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Context: There was an Instagram post about unp...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A little background. I'm a far from rich guy w...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TL;DR: sister's husband recently purchased a (...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7799</th>\n",
       "      <td>*Mobile, sorry in advance\\n\\nBackground: I’m a...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7801</th>\n",
       "      <td>So this is pretty long so I’ll get right into ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7802</th>\n",
       "      <td>Right then: first the setting. My condo has al...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7803</th>\n",
       "      <td>Got into an argument with my dad about eating ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804</th>\n",
       "      <td>My partner smokes, although I’m honestly not b...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5738 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text binarized_label  \\\n",
       "0     Backstory: So, I got an Xbox one for Christmas...           RIGHT   \n",
       "1     I work with about six other people at might jo...           RIGHT   \n",
       "2     Context: There was an Instagram post about unp...           RIGHT   \n",
       "4     A little background. I'm a far from rich guy w...           RIGHT   \n",
       "5     TL;DR: sister's husband recently purchased a (...           RIGHT   \n",
       "...                                                 ...             ...   \n",
       "7799  *Mobile, sorry in advance\\n\\nBackground: I’m a...           RIGHT   \n",
       "7801  So this is pretty long so I’ll get right into ...           RIGHT   \n",
       "7802  Right then: first the setting. My condo has al...           RIGHT   \n",
       "7803  Got into an argument with my dad about eating ...           RIGHT   \n",
       "7804  My partner smokes, although I’m honestly not b...           RIGHT   \n",
       "\n",
       "      num_binarized_label  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "4                       0  \n",
       "5                       0  \n",
       "...                   ...  \n",
       "7799                    0  \n",
       "7801                    0  \n",
       "7802                    0  \n",
       "7803                    0  \n",
       "7804                    0  \n",
       "\n",
       "[5738 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbl0 = train_df['num_binarized_label'] == 0\n",
    "train_df_new = pd.DataFrame(train_df[nbl0]) # dataframe that only contains '0' as num_binarized_label\n",
    "#train_df_new\n",
    "train_df_0 = train_df_new.iloc[:5738]\n",
    "train_df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2eRPf-uA2R0b"
   },
   "outputs": [],
   "source": [
    "balance_train_df = train_df_0.append(train_df_1, ignore_index=True)\n",
    "#balance_train_df\n",
    "train_df = balance_train_df.sample(frac = 1) # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "x1kBqTZeq0LF",
    "outputId": "b6476b86-15dd-461c-e303-4c1a594908c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binarized_label</th>\n",
       "      <th>num_binarized_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11016</th>\n",
       "      <td>Greetings. will probably delete this post beca...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>So I had this friend that was heavy into drugs...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>So my mom never developed good eating habits, ...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>My dad and his wife have a vacation condo at t...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>So, I recently had surgery on my foot, I had a...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>I hope this I see the right type of post for t...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>Hey AITA, long time first time, etc etc. I am ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>So, some background, i am 14m so am obviously ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7881</th>\n",
       "      <td>Now, this already sounds pretty bad for me, bu...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>1st time poster, sorry for being anxious/any m...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text binarized_label  \\\n",
       "11016  Greetings. will probably delete this post beca...           WRONG   \n",
       "1862   So I had this friend that was heavy into drugs...           RIGHT   \n",
       "6131   So my mom never developed good eating habits, ...           WRONG   \n",
       "3020   My dad and his wife have a vacation condo at t...           RIGHT   \n",
       "3637   So, I recently had surgery on my foot, I had a...           RIGHT   \n",
       "...                                                  ...             ...   \n",
       "3139   I hope this I see the right type of post for t...           RIGHT   \n",
       "3324   Hey AITA, long time first time, etc etc. I am ...           RIGHT   \n",
       "926    So, some background, i am 14m so am obviously ...           RIGHT   \n",
       "7881   Now, this already sounds pretty bad for me, bu...           WRONG   \n",
       "2181   1st time poster, sorry for being anxious/any m...           RIGHT   \n",
       "\n",
       "       num_binarized_label  \n",
       "11016                    1  \n",
       "1862                     0  \n",
       "6131                     1  \n",
       "3020                     0  \n",
       "3637                     0  \n",
       "...                    ...  \n",
       "3139                     0  \n",
       "3324                     0  \n",
       "926                      0  \n",
       "7881                     1  \n",
       "2181                     0  \n",
       "\n",
       "[11476 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "cyfZWryt3Lt4",
    "outputId": "2cd04392-86ac-4d73-d08f-5a1e725f6afd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binarized_label</th>\n",
       "      <th>num_binarized_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11016</th>\n",
       "      <td>Greetings. will probably delete this post beca...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>So I had this friend that was heavy into drugs...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>So my mom never developed good eating habits, ...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>My dad and his wife have a vacation condo at t...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>So, I recently had surgery on my foot, I had a...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>I hope this I see the right type of post for t...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>Hey AITA, long time first time, etc etc. I am ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>So, some background, i am 14m so am obviously ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7881</th>\n",
       "      <td>Now, this already sounds pretty bad for me, bu...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>1st time poster, sorry for being anxious/any m...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text binarized_label  \\\n",
       "11016  Greetings. will probably delete this post beca...           WRONG   \n",
       "1862   So I had this friend that was heavy into drugs...           RIGHT   \n",
       "6131   So my mom never developed good eating habits, ...           WRONG   \n",
       "3020   My dad and his wife have a vacation condo at t...           RIGHT   \n",
       "3637   So, I recently had surgery on my foot, I had a...           RIGHT   \n",
       "...                                                  ...             ...   \n",
       "3139   I hope this I see the right type of post for t...           RIGHT   \n",
       "3324   Hey AITA, long time first time, etc etc. I am ...           RIGHT   \n",
       "926    So, some background, i am 14m so am obviously ...           RIGHT   \n",
       "7881   Now, this already sounds pretty bad for me, bu...           WRONG   \n",
       "2181   1st time poster, sorry for being anxious/any m...           RIGHT   \n",
       "\n",
       "       num_binarized_label  \n",
       "11016                    1  \n",
       "1862                     0  \n",
       "6131                     1  \n",
       "3020                     0  \n",
       "3637                     0  \n",
       "...                    ...  \n",
       "3139                     0  \n",
       "3324                     0  \n",
       "926                      0  \n",
       "7881                     1  \n",
       "2181                     0  \n",
       "\n",
       "[11476 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5c18o1K2bo01"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #Remove emojis and special chars\n",
    "    clean=text\n",
    "    #reg = re.compile('\\\\.+?(?=\\B|$)')\n",
    "    #clean = text.apply(lambda r: re.sub(reg, string=r, repl=''))\n",
    "    #reg = re.compile('\\x89Û_')\n",
    "    #clean = clean.apply(lambda r: re.sub(reg, string=r, repl=' '))\n",
    "    reg = re.compile('\\&amp')\n",
    "    clean = clean.apply(lambda r: re.sub(reg, string=r, repl='&'))\n",
    "    reg = re.compile('\\\\n')\n",
    "    clean = clean.apply(lambda r: re.sub(reg, string=r, repl=' '))\n",
    "    \n",
    "    #Remove hashtag symbol (#)\n",
    "    #clean = clean.apply(lambda r: r.replace('#', ''))\n",
    "\n",
    "    #Remove user names\n",
    "    reg = re.compile('@[a-zA-Z0-9\\_]+')\n",
    "    clean = clean.apply(lambda r: re.sub(reg, string=r, repl='@'))\n",
    "\n",
    "    #Remove URLs\n",
    "    reg = re.compile('https?\\S+(?=\\s|$)')\n",
    "    clean = clean.apply(lambda r: re.sub(reg, string=r, repl='www'))\n",
    "\n",
    "    #Lowercase\n",
    "    #clean = clean.apply(lambda r: r.lower())\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "S2FiZCn8nH1P"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.replace(np.nan, '', regex=True)\n",
    "\n",
    "dev_df = dev_df.replace(np.nan, '', regex=True)\n",
    "\n",
    "test_df = test_df.replace(np.nan, '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "soOLE6zFbqiP"
   },
   "outputs": [],
   "source": [
    "train_df['clean'] = clean_text(train_df['text'])\n",
    "dev_df['clean'] = clean_text(dev_df['text'])\n",
    "test_df['clean'] = clean_text(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MgvH0C9-ncI6",
    "outputId": "1ff73bd7-4101-4e54-8cbf-b8ec21111191"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binarized_label</th>\n",
       "      <th>num_binarized_label</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11016</th>\n",
       "      <td>Greetings. will probably delete this post beca...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>Greetings. will probably delete this post beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>So I had this friend that was heavy into drugs...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>So I had this friend that was heavy into drugs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>So my mom never developed good eating habits, ...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>So my mom never developed good eating habits, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>My dad and his wife have a vacation condo at t...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>My dad and his wife have a vacation condo at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>So, I recently had surgery on my foot, I had a...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>So, I recently had surgery on my foot, I had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>I hope this I see the right type of post for t...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>I hope this I see the right type of post for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>Hey AITA, long time first time, etc etc. I am ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey AITA, long time first time, etc etc. I am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>So, some background, i am 14m so am obviously ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>So, some background, i am 14m so am obviously ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7881</th>\n",
       "      <td>Now, this already sounds pretty bad for me, bu...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>Now, this already sounds pretty bad for me, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>1st time poster, sorry for being anxious/any m...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>1st time poster, sorry for being anxious/any m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11476 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text binarized_label  \\\n",
       "11016  Greetings. will probably delete this post beca...           WRONG   \n",
       "1862   So I had this friend that was heavy into drugs...           RIGHT   \n",
       "6131   So my mom never developed good eating habits, ...           WRONG   \n",
       "3020   My dad and his wife have a vacation condo at t...           RIGHT   \n",
       "3637   So, I recently had surgery on my foot, I had a...           RIGHT   \n",
       "...                                                  ...             ...   \n",
       "3139   I hope this I see the right type of post for t...           RIGHT   \n",
       "3324   Hey AITA, long time first time, etc etc. I am ...           RIGHT   \n",
       "926    So, some background, i am 14m so am obviously ...           RIGHT   \n",
       "7881   Now, this already sounds pretty bad for me, bu...           WRONG   \n",
       "2181   1st time poster, sorry for being anxious/any m...           RIGHT   \n",
       "\n",
       "       num_binarized_label                                              clean  \n",
       "11016                    1  Greetings. will probably delete this post beca...  \n",
       "1862                     0  So I had this friend that was heavy into drugs...  \n",
       "6131                     1  So my mom never developed good eating habits, ...  \n",
       "3020                     0  My dad and his wife have a vacation condo at t...  \n",
       "3637                     0  So, I recently had surgery on my foot, I had a...  \n",
       "...                    ...                                                ...  \n",
       "3139                     0  I hope this I see the right type of post for t...  \n",
       "3324                     0  Hey AITA, long time first time, etc etc. I am ...  \n",
       "926                      0  So, some background, i am 14m so am obviously ...  \n",
       "7881                     1  Now, this already sounds pretty bad for me, bu...  \n",
       "2181                     0  1st time poster, sorry for being anxious/any m...  \n",
       "\n",
       "[11476 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1omAf1cd6Nh",
    "outputId": "e8df7c7e-4f5f-47a3-b2de-497876237e91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"   Throwaway for obvious reasons.     I dropped out of uni 2 years ago because I was planning on moving to a different country and going to Uni there. However, my parents didn't want to help me in any way and I couldn't afford it myself. They've always supported my younger sister though, bought her an apartment and they're even paying her bills, even though she earns enough money to do that herself. So atm I'm stuck at home with them, which sucks as I am 25 yo and I feel like I'm wasting my life completely.     Both my parents were extremely abusive, especially my dad. As a result, I have social anxiety, trust issues, panic attacks etc. I can deal with everything as I got used to it anyway, but lately things have gotten worse.     A few years ago my dad was diagnosed with type II diabetes, and he retired. He's been staying at home ever since and he's slowly but surely becoming a vegetable. He had a stroke which left him unable to speak/walk properly. I'm no doctor, but I found his hospital records and even talked to a nurse, and she said he's a bloody mess and he could die at any time. The worst part is, he doesn't realise what's happening around him anymore. He leaves the apartment door open at night, he forgets stuff on the stove, and he makes a huge mess everywhere. I talked to my mum about this, I don't feel safe with him around. He clearly lost his mind but she refuses to acknowledge it. Throughout the years, I've tried to tell her there's something really wrong with him, but she always just shrugged it off. He was an awful husband, so she doesn't love him, but she says she feels pity for him.     I suggested we put him in a retirement home, as he clearly cannot take care of himself and he's putting our lives in danger. I sleep with ear plugs because he slams doors/drops things all the time. I'm afraid he might set our apartment on fire or worse. My mum doesn't want to do that because she's afraid of his reaction; she thinks he's going to get a heart attack if she tries to bring it up. He's always hated hospitals and he always refused treatment, even when he got bitten by a stray dog, even after his stroke, so I see where my mum is coming from. However, I've had enough.     Yesterday I heard him choke, he was struggling to breathe and honestly, it sounded like he was gonna die. And I was relieved. My first instinct wasn't to help him, instead I kept doing my skincare, honestly hoping he'd just die already. He didn't. I told my mum what happened when she got home and she thinks I'm a monster. But am I really? This person has abused me my entire life, has beaten the living shit out of me, hell he has even tried to kill me a few times. I know my life would get better if he died, my mum would sell our apartment and I'd finally have money to go to college and start my own life. So AITA for wanting my abusive father gone?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['clean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8SlXUh6eaouY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6inA2y46ayU3"
   },
   "source": [
    "# **Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ta4HcJDXi80-",
    "outputId": "45b68a28-a997-4d05-94e3-9379fd9a085b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binarized_label</th>\n",
       "      <th>num_binarized_label</th>\n",
       "      <th>clean</th>\n",
       "      <th>lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11016</th>\n",
       "      <td>Greetings. will probably delete this post beca...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>Greetings. will probably delete this post beca...</td>\n",
       "      <td>greetings. will probably delete this post beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>So I had this friend that was heavy into drugs...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>So I had this friend that was heavy into drugs...</td>\n",
       "      <td>so i had this friend that was heavy into drugs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>So my mom never developed good eating habits, ...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>So my mom never developed good eating habits, ...</td>\n",
       "      <td>so my mom never developed good eating habits, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>My dad and his wife have a vacation condo at t...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>My dad and his wife have a vacation condo at t...</td>\n",
       "      <td>my dad and his wife have a vacation condo at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>So, I recently had surgery on my foot, I had a...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>So, I recently had surgery on my foot, I had a...</td>\n",
       "      <td>so, i recently had surgery on my foot, i had a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text binarized_label  \\\n",
       "11016  Greetings. will probably delete this post beca...           WRONG   \n",
       "1862   So I had this friend that was heavy into drugs...           RIGHT   \n",
       "6131   So my mom never developed good eating habits, ...           WRONG   \n",
       "3020   My dad and his wife have a vacation condo at t...           RIGHT   \n",
       "3637   So, I recently had surgery on my foot, I had a...           RIGHT   \n",
       "\n",
       "       num_binarized_label                                              clean  \\\n",
       "11016                    1  Greetings. will probably delete this post beca...   \n",
       "1862                     0  So I had this friend that was heavy into drugs...   \n",
       "6131                     1  So my mom never developed good eating habits, ...   \n",
       "3020                     0  My dad and his wife have a vacation condo at t...   \n",
       "3637                     0  So, I recently had surgery on my foot, I had a...   \n",
       "\n",
       "                                                   lower  \n",
       "11016  greetings. will probably delete this post beca...  \n",
       "1862   so i had this friend that was heavy into drugs...  \n",
       "6131   so my mom never developed good eating habits, ...  \n",
       "3020   my dad and his wife have a vacation condo at t...  \n",
       "3637   so, i recently had surgery on my foot, i had a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"lower\"] = train_df[\"clean\"].apply(lambda x: x.lower())\n",
    "\n",
    "dev_df[\"lower\"] = dev_df[\"clean\"].apply(lambda x: x.lower())\n",
    "\n",
    "test_df[\"lower\"] = test_df[\"clean\"].apply(lambda x: x.lower())\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8a01ZoVi8yh",
    "outputId": "b8bb3954-44a2-4759-c0ab-81fe50c7b217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: contractions in ./jp1/lib/python3.10/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in ./jp1/lib/python3.10/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in ./jp1/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
      "Requirement already satisfied: pyahocorasick in ./jp1/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (1.4.4+computecanada)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "import contractions\n",
    "\n",
    "train_df[\"lower\"] = train_df[\"lower\"].apply(lambda x: contractions.fix(x))\n",
    "dev_df[\"lower\"] = dev_df[\"lower\"].apply(lambda x: contractions.fix(x))\n",
    "test_df[\"lower\"] = test_df[\"lower\"].apply(lambda x: contractions.fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "nJHpsc2homtd"
   },
   "outputs": [],
   "source": [
    "def remove_non_ascii(text):\n",
    "    \"\"\"\n",
    "        Remove non-ASCII characters \n",
    "    \"\"\"\n",
    "    return re.sub(r'[^\\x00-\\x7f]',r'', text) # or ''.join([x for x in text if x in string.printable]) \n",
    "\n",
    "# remove non-ascii characters from the text\n",
    "\n",
    "train_df[\"lower\"] = train_df[\"lower\"].apply(lambda x: remove_non_ascii(x))\n",
    "dev_df[\"lower\"] = dev_df[\"lower\"].apply(lambda x: remove_non_ascii(x))\n",
    "test_df[\"lower\"] = test_df[\"lower\"].apply(lambda x: remove_non_ascii(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Jv6RO3iKop6o"
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    \"\"\"\n",
    "        Remove special special characters, including symbols, emojis, and other graphic characters\n",
    "    \"\"\"\n",
    "    emoji_pattern = re.compile(\n",
    "        '['\n",
    "        u'\\U0001F600-\\U0001F64F'  # emoticons\n",
    "        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
    "        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
    "        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n",
    "        u'\\U00002702-\\U000027B0'\n",
    "        u'\\U000024C2-\\U0001F251'\n",
    "        ']+',\n",
    "        flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "# remove non-ascii characters from the text\n",
    "\n",
    "train_df[\"lower\"] = train_df[\"lower\"].apply(lambda x: remove_special_characters(x))\n",
    "dev_df[\"lower\"] = dev_df[\"lower\"].apply(lambda x: remove_special_characters(x))\n",
    "test_df[\"lower\"] = test_df[\"lower\"].apply(lambda x: remove_special_characters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caTZ_mtZEmIZ",
    "outputId": "f5f4cf83-3781-4218-901e-5647fec4da19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/zhe8nov1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "5EwtF6_kEFKs"
   },
   "outputs": [],
   "source": [
    "# Tokenizing the tweet base texts.\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "train_df['tokenized'] = train_df['lower'].apply(word_tokenize)\n",
    "dev_df['tokenized'] = dev_df['lower'].apply(word_tokenize)\n",
    "test_df['tokenized'] = test_df['lower'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASAwOzNfEFFq",
    "outputId": "80d230d0-86c2-4cf9-8eb4-1fc49fa586cb"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "def snowball_stemmer(text):\n",
    "    \"\"\"\n",
    "        Stem words in list of tokenized words with SnowballStemmer\n",
    "    \"\"\"\n",
    "    stemmer = nltk.SnowballStemmer(\"english\")\n",
    "    stems = [stemmer.stem(i) for i in text]\n",
    "    return stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcsmJA_aGdnj",
    "outputId": "7d1c57ca-d329-4e85-fd65-644e1cf35b52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zhe8nov1/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zhe8nov1/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "bSfB3aFyE7Y8"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatize_word(text):\n",
    "    \"\"\"\n",
    "        Lemmatize the tokenized words\n",
    "    \"\"\"\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma = [lemmatizer.lemmatize(word, tag) for word, tag in text]\n",
    "    return lemma\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "train_df['lemmatize_word_wo_pos'] = train_df['tokenized'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "\n",
    "dev_df['lemmatize_word_wo_pos'] = dev_df['tokenized'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "\n",
    "test_df['lemmatize_word_wo_pos'] = test_df['tokenized'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-y8ZnATKE7O9"
   },
   "outputs": [],
   "source": [
    "connect1 = []\n",
    "for i in train_df['lemmatize_word_wo_pos']:\n",
    "  connect1.append(' '.join(i))\n",
    "train_df['clean1'] = connect1\n",
    "\n",
    "\n",
    "connect2 = []\n",
    "for i in dev_df['lemmatize_word_wo_pos']:\n",
    "  connect2.append(' '.join(i))\n",
    "dev_df['clean1'] = connect2\n",
    "\n",
    "\n",
    "connect3 = []\n",
    "for i in test_df['lemmatize_word_wo_pos']:\n",
    "  connect3.append(' '.join(i))\n",
    "test_df['clean1'] = connect3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzhA3WzaKylJ",
    "outputId": "89f7cebd-c693-4e4f-de30-1e27e44bb405"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My boyfriend (well just call him M) and I are creators on Instagram (he is also on TikTok). I\\'m a digital and traditional artist and in one of my classes we create t shirts and things (socks, lanyards, water bottles, stickers, you name it). I\\'m a big fan of putting my art on t shirts so I can sell them.  M wanted to make some posts for TikTok and wanted to use the shirt I made today. My one personal rule is that if the shirt isn\\'t being given to someone else, then I wear it first (this is because I know I wont get it back. Ive made one other shirt that I\\'ve worn, and he wore it for a week and hasn\\'t given it back.) So I told him no, because I haven\\'t worn the shirt yet.   M proceeded to complain about not having content to post, and how his IG post today didn\\'t get any engagement, saying \"of course you dont know, because you never look.\"  Am I the asshole for wanting to wear the shirt I made just once?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df['clean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOt-23ZRE7Tx",
    "outputId": "b89688c3-0f40-4a59-9889-5d3c290c9dd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binarized_label</th>\n",
       "      <th>num_binarized_label</th>\n",
       "      <th>clean</th>\n",
       "      <th>lower</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatize_word_wo_pos</th>\n",
       "      <th>clean1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My boyfriend (well just call him M) and I are ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>My boyfriend (well just call him M) and I are ...</td>\n",
       "      <td>my boyfriend (well just call him m) and i are ...</td>\n",
       "      <td>[my, boyfriend, (, well, just, call, him, m, )...</td>\n",
       "      <td>[my, boyfriend, (, well, just, call, him, m, )...</td>\n",
       "      <td>my boyfriend ( well just call him m ) and i ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nMy really good friend is getting married....</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>My really good friend is getting married. Y...</td>\n",
       "      <td>my really good friend is getting married. y...</td>\n",
       "      <td>[my, really, good, friend, is, getting, marrie...</td>\n",
       "      <td>[my, really, good, friend, is, getting, marrie...</td>\n",
       "      <td>my really good friend is getting married . yay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've been very lonely for a long time, few fri...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>I've been very lonely for a long time, few fri...</td>\n",
       "      <td>i have been very lonely for a long time, few f...</td>\n",
       "      <td>[i, have, been, very, lonely, for, a, long, ti...</td>\n",
       "      <td>[i, have, been, very, lonely, for, a, long, ti...</td>\n",
       "      <td>i have been very lonely for a long time , few ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alt account because friends know my real one. ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>Alt account because friends know my real one. ...</td>\n",
       "      <td>alt account because friends know my real one. ...</td>\n",
       "      <td>[alt, account, because, friends, know, my, rea...</td>\n",
       "      <td>[alt, account, because, friend, know, my, real...</td>\n",
       "      <td>alt account because friend know my real one . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pretty much was hanging out with two friends. ...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>Pretty much was hanging out with two friends. ...</td>\n",
       "      <td>pretty much was hanging out with two friends. ...</td>\n",
       "      <td>[pretty, much, was, hanging, out, with, two, f...</td>\n",
       "      <td>[pretty, much, wa, hanging, out, with, two, fr...</td>\n",
       "      <td>pretty much wa hanging out with two friend . i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>For reference we're both juniors at a T20 coll...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>For reference we're both juniors at a T20 coll...</td>\n",
       "      <td>for reference we are both juniors at a t20 col...</td>\n",
       "      <td>[for, reference, we, are, both, juniors, at, a...</td>\n",
       "      <td>[for, reference, we, are, both, junior, at, a,...</td>\n",
       "      <td>for reference we are both junior at a t20 coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>So this just happened and I'm a little taken a...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>So this just happened and I'm a little taken a...</td>\n",
       "      <td>so this just happened and i am a little taken ...</td>\n",
       "      <td>[so, this, just, happened, and, i, am, a, litt...</td>\n",
       "      <td>[so, this, just, happened, and, i, am, a, litt...</td>\n",
       "      <td>so this just happened and i am a little taken ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>So, I've been friends with someone for a few y...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>So, I've been friends with someone for a few y...</td>\n",
       "      <td>so, i have been friends with someone for a few...</td>\n",
       "      <td>[so, ,, i, have, been, friends, with, someone,...</td>\n",
       "      <td>[so, ,, i, have, been, friend, with, someone, ...</td>\n",
       "      <td>so , i have been friend with someone for a few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>My first post!\\n\\nNo words were exchanged in t...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>My first post!  No words were exchanged in thi...</td>\n",
       "      <td>my first post!  no words were exchanged in thi...</td>\n",
       "      <td>[my, first, post, !, no, words, were, exchange...</td>\n",
       "      <td>[my, first, post, !, no, word, were, exchanged...</td>\n",
       "      <td>my first post ! no word were exchanged in this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Background info: I’m in college and my dorm is...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>Background info: I’m in college and my dorm is...</td>\n",
       "      <td>background info: i am in college and my dorm i...</td>\n",
       "      <td>[background, info, :, i, am, in, college, and,...</td>\n",
       "      <td>[background, info, :, i, am, in, college, and,...</td>\n",
       "      <td>background info : i am in college and my dorm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2343 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text binarized_label  \\\n",
       "0     My boyfriend (well just call him M) and I are ...           RIGHT   \n",
       "2      \\n\\nMy really good friend is getting married....           RIGHT   \n",
       "3     I've been very lonely for a long time, few fri...           RIGHT   \n",
       "4     Alt account because friends know my real one. ...           RIGHT   \n",
       "5     Pretty much was hanging out with two friends. ...           WRONG   \n",
       "...                                                 ...             ...   \n",
       "2494  For reference we're both juniors at a T20 coll...           WRONG   \n",
       "2495  So this just happened and I'm a little taken a...           WRONG   \n",
       "2497  So, I've been friends with someone for a few y...           RIGHT   \n",
       "2498  My first post!\\n\\nNo words were exchanged in t...           RIGHT   \n",
       "2499  Background info: I’m in college and my dorm is...           WRONG   \n",
       "\n",
       "      num_binarized_label                                              clean  \\\n",
       "0                       0  My boyfriend (well just call him M) and I are ...   \n",
       "2                       0     My really good friend is getting married. Y...   \n",
       "3                       0  I've been very lonely for a long time, few fri...   \n",
       "4                       0  Alt account because friends know my real one. ...   \n",
       "5                       1  Pretty much was hanging out with two friends. ...   \n",
       "...                   ...                                                ...   \n",
       "2494                    1  For reference we're both juniors at a T20 coll...   \n",
       "2495                    1  So this just happened and I'm a little taken a...   \n",
       "2497                    0  So, I've been friends with someone for a few y...   \n",
       "2498                    0  My first post!  No words were exchanged in thi...   \n",
       "2499                    1  Background info: I’m in college and my dorm is...   \n",
       "\n",
       "                                                  lower  \\\n",
       "0     my boyfriend (well just call him m) and i are ...   \n",
       "2        my really good friend is getting married. y...   \n",
       "3     i have been very lonely for a long time, few f...   \n",
       "4     alt account because friends know my real one. ...   \n",
       "5     pretty much was hanging out with two friends. ...   \n",
       "...                                                 ...   \n",
       "2494  for reference we are both juniors at a t20 col...   \n",
       "2495  so this just happened and i am a little taken ...   \n",
       "2497  so, i have been friends with someone for a few...   \n",
       "2498  my first post!  no words were exchanged in thi...   \n",
       "2499  background info: i am in college and my dorm i...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "0     [my, boyfriend, (, well, just, call, him, m, )...   \n",
       "2     [my, really, good, friend, is, getting, marrie...   \n",
       "3     [i, have, been, very, lonely, for, a, long, ti...   \n",
       "4     [alt, account, because, friends, know, my, rea...   \n",
       "5     [pretty, much, was, hanging, out, with, two, f...   \n",
       "...                                                 ...   \n",
       "2494  [for, reference, we, are, both, juniors, at, a...   \n",
       "2495  [so, this, just, happened, and, i, am, a, litt...   \n",
       "2497  [so, ,, i, have, been, friends, with, someone,...   \n",
       "2498  [my, first, post, !, no, words, were, exchange...   \n",
       "2499  [background, info, :, i, am, in, college, and,...   \n",
       "\n",
       "                                  lemmatize_word_wo_pos  \\\n",
       "0     [my, boyfriend, (, well, just, call, him, m, )...   \n",
       "2     [my, really, good, friend, is, getting, marrie...   \n",
       "3     [i, have, been, very, lonely, for, a, long, ti...   \n",
       "4     [alt, account, because, friend, know, my, real...   \n",
       "5     [pretty, much, wa, hanging, out, with, two, fr...   \n",
       "...                                                 ...   \n",
       "2494  [for, reference, we, are, both, junior, at, a,...   \n",
       "2495  [so, this, just, happened, and, i, am, a, litt...   \n",
       "2497  [so, ,, i, have, been, friend, with, someone, ...   \n",
       "2498  [my, first, post, !, no, word, were, exchanged...   \n",
       "2499  [background, info, :, i, am, in, college, and,...   \n",
       "\n",
       "                                                 clean1  \n",
       "0     my boyfriend ( well just call him m ) and i ar...  \n",
       "2     my really good friend is getting married . yay...  \n",
       "3     i have been very lonely for a long time , few ...  \n",
       "4     alt account because friend know my real one . ...  \n",
       "5     pretty much wa hanging out with two friend . i...  \n",
       "...                                                 ...  \n",
       "2494  for reference we are both junior at a t20 coll...  \n",
       "2495  so this just happened and i am a little taken ...  \n",
       "2497  so , i have been friend with someone for a few...  \n",
       "2498  my first post ! no word were exchanged in this...  \n",
       "2499  background info : i am in college and my dorm ...  \n",
       "\n",
       "[2343 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fNXEbcJpNCT",
    "outputId": "ba6c4c19-d9c9-4e88-d38d-5ac3478ece56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binarized_label</th>\n",
       "      <th>num_binarized_label</th>\n",
       "      <th>clean</th>\n",
       "      <th>lower</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatize_word_wo_pos</th>\n",
       "      <th>clean1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11016</th>\n",
       "      <td>Greetings. will probably delete this post beca...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>Greetings. will probably delete this post beca...</td>\n",
       "      <td>greetings. will probably delete this post beca...</td>\n",
       "      <td>[greetings, ., will, probably, delete, this, p...</td>\n",
       "      <td>[greeting, ., will, probably, delete, this, po...</td>\n",
       "      <td>greeting . will probably delete this post beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>So I had this friend that was heavy into drugs...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>So I had this friend that was heavy into drugs...</td>\n",
       "      <td>so i had this friend that was heavy into drugs...</td>\n",
       "      <td>[so, i, had, this, friend, that, was, heavy, i...</td>\n",
       "      <td>[so, i, had, this, friend, that, wa, heavy, in...</td>\n",
       "      <td>so i had this friend that wa heavy into drug ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>So my mom never developed good eating habits, ...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>So my mom never developed good eating habits, ...</td>\n",
       "      <td>so my mom never developed good eating habits, ...</td>\n",
       "      <td>[so, my, mom, never, developed, good, eating, ...</td>\n",
       "      <td>[so, my, mom, never, developed, good, eating, ...</td>\n",
       "      <td>so my mom never developed good eating habit , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>My dad and his wife have a vacation condo at t...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>My dad and his wife have a vacation condo at t...</td>\n",
       "      <td>my dad and his wife have a vacation condo at t...</td>\n",
       "      <td>[my, dad, and, his, wife, have, a, vacation, c...</td>\n",
       "      <td>[my, dad, and, his, wife, have, a, vacation, c...</td>\n",
       "      <td>my dad and his wife have a vacation condo at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>So, I recently had surgery on my foot, I had a...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>So, I recently had surgery on my foot, I had a...</td>\n",
       "      <td>so, i recently had surgery on my foot, i had a...</td>\n",
       "      <td>[so, ,, i, recently, had, surgery, on, my, foo...</td>\n",
       "      <td>[so, ,, i, recently, had, surgery, on, my, foo...</td>\n",
       "      <td>so , i recently had surgery on my foot , i had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>I hope this I see the right type of post for t...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>I hope this I see the right type of post for t...</td>\n",
       "      <td>i hope this i see the right type of post for t...</td>\n",
       "      <td>[i, hope, this, i, see, the, right, type, of, ...</td>\n",
       "      <td>[i, hope, this, i, see, the, right, type, of, ...</td>\n",
       "      <td>i hope this i see the right type of post for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>Hey AITA, long time first time, etc etc. I am ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey AITA, long time first time, etc etc. I am ...</td>\n",
       "      <td>hey aita, long time first time, etc etc. i am ...</td>\n",
       "      <td>[hey, aita, ,, long, time, first, time, ,, etc...</td>\n",
       "      <td>[hey, aita, ,, long, time, first, time, ,, etc...</td>\n",
       "      <td>hey aita , long time first time , etc etc . i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>So, some background, i am 14m so am obviously ...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>So, some background, i am 14m so am obviously ...</td>\n",
       "      <td>so, some background, i am 14m so am obviously ...</td>\n",
       "      <td>[so, ,, some, background, ,, i, am, 14m, so, a...</td>\n",
       "      <td>[so, ,, some, background, ,, i, am, 14m, so, a...</td>\n",
       "      <td>so , some background , i am 14m so am obviousl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7881</th>\n",
       "      <td>Now, this already sounds pretty bad for me, bu...</td>\n",
       "      <td>WRONG</td>\n",
       "      <td>1</td>\n",
       "      <td>Now, this already sounds pretty bad for me, bu...</td>\n",
       "      <td>now, this already sounds pretty bad for me, bu...</td>\n",
       "      <td>[now, ,, this, already, sounds, pretty, bad, f...</td>\n",
       "      <td>[now, ,, this, already, sound, pretty, bad, fo...</td>\n",
       "      <td>now , this already sound pretty bad for me , b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>1st time poster, sorry for being anxious/any m...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0</td>\n",
       "      <td>1st time poster, sorry for being anxious/any m...</td>\n",
       "      <td>1st time poster, sorry for being anxious/any m...</td>\n",
       "      <td>[1st, time, poster, ,, sorry, for, being, anxi...</td>\n",
       "      <td>[1st, time, poster, ,, sorry, for, being, anxi...</td>\n",
       "      <td>1st time poster , sorry for being anxious/any ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11476 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text binarized_label  \\\n",
       "11016  Greetings. will probably delete this post beca...           WRONG   \n",
       "1862   So I had this friend that was heavy into drugs...           RIGHT   \n",
       "6131   So my mom never developed good eating habits, ...           WRONG   \n",
       "3020   My dad and his wife have a vacation condo at t...           RIGHT   \n",
       "3637   So, I recently had surgery on my foot, I had a...           RIGHT   \n",
       "...                                                  ...             ...   \n",
       "3139   I hope this I see the right type of post for t...           RIGHT   \n",
       "3324   Hey AITA, long time first time, etc etc. I am ...           RIGHT   \n",
       "926    So, some background, i am 14m so am obviously ...           RIGHT   \n",
       "7881   Now, this already sounds pretty bad for me, bu...           WRONG   \n",
       "2181   1st time poster, sorry for being anxious/any m...           RIGHT   \n",
       "\n",
       "       num_binarized_label                                              clean  \\\n",
       "11016                    1  Greetings. will probably delete this post beca...   \n",
       "1862                     0  So I had this friend that was heavy into drugs...   \n",
       "6131                     1  So my mom never developed good eating habits, ...   \n",
       "3020                     0  My dad and his wife have a vacation condo at t...   \n",
       "3637                     0  So, I recently had surgery on my foot, I had a...   \n",
       "...                    ...                                                ...   \n",
       "3139                     0  I hope this I see the right type of post for t...   \n",
       "3324                     0  Hey AITA, long time first time, etc etc. I am ...   \n",
       "926                      0  So, some background, i am 14m so am obviously ...   \n",
       "7881                     1  Now, this already sounds pretty bad for me, bu...   \n",
       "2181                     0  1st time poster, sorry for being anxious/any m...   \n",
       "\n",
       "                                                   lower  \\\n",
       "11016  greetings. will probably delete this post beca...   \n",
       "1862   so i had this friend that was heavy into drugs...   \n",
       "6131   so my mom never developed good eating habits, ...   \n",
       "3020   my dad and his wife have a vacation condo at t...   \n",
       "3637   so, i recently had surgery on my foot, i had a...   \n",
       "...                                                  ...   \n",
       "3139   i hope this i see the right type of post for t...   \n",
       "3324   hey aita, long time first time, etc etc. i am ...   \n",
       "926    so, some background, i am 14m so am obviously ...   \n",
       "7881   now, this already sounds pretty bad for me, bu...   \n",
       "2181   1st time poster, sorry for being anxious/any m...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "11016  [greetings, ., will, probably, delete, this, p...   \n",
       "1862   [so, i, had, this, friend, that, was, heavy, i...   \n",
       "6131   [so, my, mom, never, developed, good, eating, ...   \n",
       "3020   [my, dad, and, his, wife, have, a, vacation, c...   \n",
       "3637   [so, ,, i, recently, had, surgery, on, my, foo...   \n",
       "...                                                  ...   \n",
       "3139   [i, hope, this, i, see, the, right, type, of, ...   \n",
       "3324   [hey, aita, ,, long, time, first, time, ,, etc...   \n",
       "926    [so, ,, some, background, ,, i, am, 14m, so, a...   \n",
       "7881   [now, ,, this, already, sounds, pretty, bad, f...   \n",
       "2181   [1st, time, poster, ,, sorry, for, being, anxi...   \n",
       "\n",
       "                                   lemmatize_word_wo_pos  \\\n",
       "11016  [greeting, ., will, probably, delete, this, po...   \n",
       "1862   [so, i, had, this, friend, that, wa, heavy, in...   \n",
       "6131   [so, my, mom, never, developed, good, eating, ...   \n",
       "3020   [my, dad, and, his, wife, have, a, vacation, c...   \n",
       "3637   [so, ,, i, recently, had, surgery, on, my, foo...   \n",
       "...                                                  ...   \n",
       "3139   [i, hope, this, i, see, the, right, type, of, ...   \n",
       "3324   [hey, aita, ,, long, time, first, time, ,, etc...   \n",
       "926    [so, ,, some, background, ,, i, am, 14m, so, a...   \n",
       "7881   [now, ,, this, already, sound, pretty, bad, fo...   \n",
       "2181   [1st, time, poster, ,, sorry, for, being, anxi...   \n",
       "\n",
       "                                                  clean1  \n",
       "11016  greeting . will probably delete this post beca...  \n",
       "1862   so i had this friend that wa heavy into drug ....  \n",
       "6131   so my mom never developed good eating habit , ...  \n",
       "3020   my dad and his wife have a vacation condo at t...  \n",
       "3637   so , i recently had surgery on my foot , i had...  \n",
       "...                                                  ...  \n",
       "3139   i hope this i see the right type of post for t...  \n",
       "3324   hey aita , long time first time , etc etc . i ...  \n",
       "926    so , some background , i am 14m so am obviousl...  \n",
       "7881   now , this already sound pretty bad for me , b...  \n",
       "2181   1st time poster , sorry for being anxious/any ...  \n",
       "\n",
       "[11476 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yTeTguvdFuK"
   },
   "source": [
    "# **Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "6NJxP_LpQNFs",
    "outputId": "2b3ce6ba-84d7-4b44-acf5-6eeb24c9a1cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"text_transformer = CountVectorizer(input='content',\\n            encoding='utf-8',\\n            decode_error='strict',\\n            preprocessor=None,\\n            tokenizer=None,\\n            token_pattern=r'(?u)\\x08\\\\w\\\\w+\\x08',\\n            max_features=None,\\n            vocabulary=None,\\n            binary=True)\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "text_transformer = TfidfVectorizer(stop_words='english', ngram_range=(1, 3), lowercase=True)\n",
    "'''text_transformer = CountVectorizer(input='content',\n",
    "            encoding='utf-8',\n",
    "            decode_error='strict',\n",
    "            preprocessor=None,\n",
    "            tokenizer=None,\n",
    "            token_pattern=r'(?u)\\b\\w\\w+\\b',\n",
    "            max_features=None,\n",
    "            vocabulary=None,\n",
    "            binary=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "75SjyfmJiZhJ"
   },
   "outputs": [],
   "source": [
    "train_x = train_df[[\"clean1\"]]\n",
    "train_y = train_df[[\"num_binarized_label\"]]\n",
    "\n",
    "dev_x = dev_df[[\"clean1\"]]\n",
    "dev_y = dev_df[[\"num_binarized_label\"]]\n",
    "\n",
    "test_x = test_df[[\"clean1\"]]\n",
    "test_y = test_df[[\"num_binarized_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "CbvwCwpjiZWY"
   },
   "outputs": [],
   "source": [
    "train_x_text = text_transformer.fit_transform(train_x['clean1'])\n",
    "dev_x_text = text_transformer.transform(dev_x['clean1'])\n",
    "test_x_text = text_transformer.transform(test_x['clean1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpZkdPutiZTJ",
    "outputId": "2b728a1b-e528-4043-f5d8-ca87fb6ea26c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11476, 2142130)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhpPGze4jW-9",
    "outputId": "749c784e-a9cd-460e-b132-328c27ad6eb7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(train_x_text,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Z4cER3_8rlf",
    "outputId": "5ecbff5f-ef23-4edc-cc78-1daed5945a5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1170  657]\n",
      " [ 246  285]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72      1827\n",
      "           1       0.30      0.54      0.39       531\n",
      "\n",
      "    accuracy                           0.62      2358\n",
      "   macro avg       0.56      0.59      0.55      2358\n",
      "weighted avg       0.71      0.62      0.65      2358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = classifier.predict(test_x_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# Making the Confusion Matrix\n",
    "print(confusion_matrix(test_y,y_pred2)) \n",
    "print(classification_report(test_y, y_pred2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "j7yAuKsPqmiH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 20:10:01\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j64xS3XlqmiI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSdBWPweqmiJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
